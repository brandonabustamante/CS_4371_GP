{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "083437a6-b852-45f1-8cef-a225f5097a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9e85a1d-cae6-4e15-a5d6-3bbd364b0735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,precision_recall_fscore_support\n",
    "from sklearn.metrics import f1_score,roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12a47fb-194f-46c4-a245-7f693f8c9258",
   "metadata": {},
   "source": [
    "# Remove before submission!!!!!!!!!\n",
    "Read the sampled CICIDS2017 dataset\n",
    "\n",
    "The CICIDS2017 dataset is publicly available at: https://www.unb.ca/cic/datasets/ids-2017.html\n",
    "Due to the large size of this dataset, the sampled subsets of CICIDS2017 is used. The subsets are in the \"data\" folder.\n",
    "If you want to use this code on other datasets (e.g., CAN-intrusion dataset), just change the dataset name and follow the same steps. The models in this code are generic models that can be used in any intrusion detection/network traffic datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e14257d8-66cc-4732-8e5d-c7b853690862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read the sampled dataset\n",
    "# df=pd.read_csv('./data/CICIDS2017_sample_km.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "810363b9-0b84-4b5b-b832-14df15b1df80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df.drop(['Label'],axis=1).values\n",
    "# y = df.iloc[:, -1].values.reshape(-1,1)\n",
    "# y=np.ravel(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8233961b-43ee-40ce-b86f-ae399c855b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X,y, train_size = 0.8, test_size = 0.2, random_state = 0,stratify = y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "82cbdc26",
   "metadata": {},
   "source": [
    "# Anomaly-based IDS\n",
    "Generate the port-scan datasets for unknown attack detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c5096b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./data/CICIDS2017_sample_km.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1849cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    18225\n",
       "3     3042\n",
       "6     2180\n",
       "1     1966\n",
       "5     1255\n",
       "2       96\n",
       "4       36\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a39b8d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[df['Label'] != 5]\n",
    "df1['Label'][df1['Label'] > 0] = 1\n",
    "df1.to_csv('./data/CICIDS2017_sample_km_without_portscan.csv',index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7217c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[df['Label'] == 5]\n",
    "df2['Label'][df2['Label'] == 5] = 1\n",
    "df2.to_csv('./data/CICIDS2017_sample_km_portscan.csv',index=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db9e4abd",
   "metadata": {},
   "source": [
    "# Read the generated datasets for unknown attack detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4acb0926",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('./data/CICIDS2017_sample_km_without_portscan.csv')\n",
    "df2 = pd.read_csv('./data/CICIDS2017_sample_km_portscan.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c40fffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df1.drop(['Label'],axis=1).dtypes[df1.dtypes != 'object'].index\n",
    "df1[features] = df1[features].apply(\n",
    "    lambda x: (x - x.mean()) / (x.std()))\n",
    "df2[features] = df2[features].apply(\n",
    "    lambda x: (x - x.mean()) / (x.std()))\n",
    "df1 = df1.fillna(0)\n",
    "df2 = df2.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6578015f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    18225\n",
       "1     7320\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6fe427d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "1    1255\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d95756c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2p=df1[df1['Label']==0]\n",
    "df2pp=df2p.sample(n=None, frac=1255/18225, replace=False, weights=None, random_state=None, axis=0)\n",
    "df2=pd.concat([df2, df2pp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d331198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "1    1255\n",
       "0    1255\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b9b1447",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85b9031d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    19480\n",
       "1     8575\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(['Label'],axis=1) .values\n",
    "y = df.iloc[:, -1].values.reshape(-1,1)\n",
    "y=np.ravel(y)\n",
    "pd.Series(y).value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d5bb415",
   "metadata": {},
   "source": [
    "### Feature engineering (IG, FCBF, and KPCA)\n",
    "Feature selection by information gain (IG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2cf8587",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "importances = mutual_info_classif(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0c587a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the sum of importance scores\n",
    "f_list = sorted(zip(map(lambda x: round(x, 4), importances), features), reverse=True)\n",
    "Sum = 0\n",
    "fs = []\n",
    "for i in range(0, len(f_list)):\n",
    "    Sum = Sum + f_list[i][0]\n",
    "    fs.append(f_list[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1380117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the important features from top to bottom until the accumulated importance reaches 90%\n",
    "f_list2 = sorted(zip(map(lambda x: round(x, 4), importances/Sum), features), reverse=True)\n",
    "Sum2 = 0\n",
    "fs = []\n",
    "for i in range(0, len(f_list2)):\n",
    "    Sum2 = Sum2 + f_list2[i][0]\n",
    "    fs.append(f_list2[i][1])\n",
    "    if Sum2>=0.9:\n",
    "        break   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c901e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fs = df[fs].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9845bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28055, 50)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1856cf70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.34612159, -0.44364535, -0.51326791, ..., -0.11333586,\n",
       "        -0.13353417, -0.05349902],\n",
       "       [-0.3443274 , -0.44364535, -0.51326791, ..., -0.11333586,\n",
       "        -0.13353417, -0.05349902],\n",
       "       [-0.3443274 , -0.44364535, -0.51326791, ..., -0.11333586,\n",
       "        -0.13353417, -0.05349902],\n",
       "       ...,\n",
       "       [-0.34461069, -0.44364535, -0.51326791, ..., -0.11333586,\n",
       "        -0.13353417, -0.05349902],\n",
       "       [-0.36859622, -0.40160229, -0.36238444, ..., -0.11333586,\n",
       "        -0.13353417, -0.04188076],\n",
       "       [-0.36859622, -0.44364535, -0.53347551, ..., -0.11333586,\n",
       "        -0.13353417, -0.05349902]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d25454e2",
   "metadata": {},
   "source": [
    "### Feature selection by Fast Correlation Based Filter (FCBF)\n",
    "\n",
    "The module is imported from the GitHub repo: https://github.com/SantiagoEG/FCBF_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75d12f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FCBF_module import FCBF, FCBFK, FCBFiP, get_i\n",
    "fcbf = FCBFK(k = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2002ec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fss = fcbf.fit_transform(X_fs,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1bf19d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28055, 20)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cad339df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.34612159, -0.53319222, -0.34935843, ..., -0.42229765,\n",
       "        -0.2803002 , -0.41947688],\n",
       "       [-0.3443274 , -0.54906516, -0.34935843, ..., -0.42229765,\n",
       "        -0.2803002 , -0.41947688],\n",
       "       [-0.3443274 , -0.55544206, -0.34935843, ..., -0.42229765,\n",
       "        -0.2803002 , -0.41947688],\n",
       "       ...,\n",
       "       [-0.34461069, -0.55544206, -0.34935843, ..., -0.42229765,\n",
       "        -0.2803002 , -0.41947688],\n",
       "       [-0.36859622, -0.56375976, -0.34935843, ..., -0.42229762,\n",
       "        -0.28030009, -0.38011427],\n",
       "       [-0.36859622, -0.07086683, -0.34935843, ..., -0.42229756,\n",
       "        -0.28029987, -0.42271216]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5625795b",
   "metadata": {},
   "source": [
    "Kernel principal component analysis (KPCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6bc6257",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede1dc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kpca = KernelPCA(n_components = 10, kernel = 'rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aa4294",
   "metadata": {},
   "outputs": [],
   "source": [
    "kpca.fit(X_fss, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbfc968",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_kpca = kpca.transform(X_fss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c1bd9f8f",
   "metadata": {},
   "source": [
    "Train-test split after feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd98152f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_kpca[:len(df1)]\n",
    "y_train = y[:len(df1)]\n",
    "X_test = X_kpca[len(df1):]\n",
    "y_test = y[len(df1):]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d599081",
   "metadata": {},
   "source": [
    "Solve class-imbalance by SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acc650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6eebac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote=SMOTE(n_jobs=-1,sampling_strategy={1:18225})\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0900ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66207cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.Series(y_test).value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5b3f42d",
   "metadata": {},
   "source": [
    "## Apply the cluster labeling (CL) k-means method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718ae556",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN,MeanShift\n",
    "from sklearn.cluster import SpectralClustering,AgglomerativeClustering,AffinityPropagation,Birch,MiniBatchKMeans,MeanShift \n",
    "from sklearn.mixture import GaussianMixture, BayesianGaussianMixture\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6808e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CL_kmeans(X_train, X_test, y_train, y_test,n,b=100):\n",
    "    km_cluster = MiniBatchKMeans(n_clusters=n,batch_size=b)\n",
    "    result = km_cluster.fit_predict(X_train)\n",
    "    result2 = km_cluster.predict(X_test)\n",
    "\n",
    "    count=0\n",
    "    a=np.zeros(n)\n",
    "    b=np.zeros(n)\n",
    "    for v in range(0,n):\n",
    "        for i in range(0,len(y_train)):\n",
    "            if result[i]==v:\n",
    "                if y_train[i]==1:\n",
    "                    a[v]=a[v]+1\n",
    "                else:\n",
    "                    b[v]=b[v]+1\n",
    "    list1=[]\n",
    "    list2=[]\n",
    "    for v in range(0,n):\n",
    "        if a[v]<=b[v]:\n",
    "            list1.append(v)\n",
    "        else: \n",
    "            list2.append(v)\n",
    "    for v in range(0,len(y_test)):\n",
    "        if result2[v] in list1:\n",
    "            result2[v]=0\n",
    "        elif result2[v] in list2:\n",
    "            result2[v]=1\n",
    "        else:\n",
    "            print(\"-1\")\n",
    "    print(classification_report(y_test, result2))\n",
    "    cm=confusion_matrix(y_test,result2)\n",
    "    acc=metrics.accuracy_score(y_test,result2)\n",
    "    print(str(acc))\n",
    "    print(cm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3cecd907",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization of CL-k-means\n",
    "Tune \"k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc45e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter optimization by BO-GP\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "from sklearn import metrics\n",
    "\n",
    "space  = [Integer(2, 50, name='n_clusters')]\n",
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    km_cluster = MiniBatchKMeans(batch_size=100, **params)\n",
    "    n=params['n_clusters']\n",
    "    \n",
    "    result = km_cluster.fit_predict(X_train)\n",
    "    result2 = km_cluster.predict(X_test)\n",
    "\n",
    "    count=0\n",
    "    a=np.zeros(n)\n",
    "    b=np.zeros(n)\n",
    "    for v in range(0,n):\n",
    "        for i in range(0,len(y_train)):\n",
    "            if result[i]==v:\n",
    "                if y_train[i]==1:\n",
    "                    a[v]=a[v]+1\n",
    "                else:\n",
    "                    b[v]=b[v]+1\n",
    "    list1=[]\n",
    "    list2=[]\n",
    "    for v in range(0,n):\n",
    "        if a[v]<=b[v]:\n",
    "            list1.append(v)\n",
    "        else: \n",
    "            list2.append(v)\n",
    "    for v in range(0,len(y_test)):\n",
    "        if result2[v] in list1:\n",
    "            result2[v]=0\n",
    "        elif result2[v] in list2:\n",
    "            result2[v]=1\n",
    "        else:\n",
    "            print(\"-1\")\n",
    "    cm=metrics.accuracy_score(y_test,result2)\n",
    "    print(str(n)+\" \"+str(cm))\n",
    "    return (1-cm)\n",
    "from skopt import gp_minimize\n",
    "import time\n",
    "t1=time.time()\n",
    "res_gp = gp_minimize(objective, space, n_calls=20, random_state=0)\n",
    "t2=time.time()\n",
    "print(t2-t1)\n",
    "print(\"Best score=%.4f\" % (1-res_gp.fun))\n",
    "print(\"\"\"Best parameters: n_clusters=%d\"\"\" % (res_gp.x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcbc5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter optimization by BO-TPE\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn import metrics\n",
    "\n",
    "def objective(params):\n",
    "    params = {\n",
    "        'n_clusters': int(params['n_clusters']), \n",
    "    }\n",
    "    km_cluster = MiniBatchKMeans(batch_size=100, **params)\n",
    "    n=params['n_clusters']\n",
    "    \n",
    "    result = km_cluster.fit_predict(X_train)\n",
    "    result2 = km_cluster.predict(X_test)\n",
    "\n",
    "    count=0\n",
    "    a=np.zeros(n)\n",
    "    b=np.zeros(n)\n",
    "    for v in range(0,n):\n",
    "        for i in range(0,len(y_train)):\n",
    "            if result[i]==v:\n",
    "                if y_train[i]==1:\n",
    "                    a[v]=a[v]+1\n",
    "                else:\n",
    "                    b[v]=b[v]+1\n",
    "    list1=[]\n",
    "    list2=[]\n",
    "    for v in range(0,n):\n",
    "        if a[v]<=b[v]:\n",
    "            list1.append(v)\n",
    "        else: \n",
    "            list2.append(v)\n",
    "    for v in range(0,len(y_test)):\n",
    "        if result2[v] in list1:\n",
    "            result2[v]=0\n",
    "        elif result2[v] in list2:\n",
    "            result2[v]=1\n",
    "        else:\n",
    "            print(\"-1\")\n",
    "    score=metrics.accuracy_score(y_test,result2)\n",
    "    print(str(params['n_clusters'])+\" \"+str(score))\n",
    "    return {'loss':1-score, 'status': STATUS_OK }\n",
    "space = {\n",
    "    'n_clusters': hp.quniform('n_clusters', 2, 50, 1),\n",
    "}\n",
    "\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20)\n",
    "print(\"Random Forest: Hyperopt estimated optimum {}\".format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedde670",
   "metadata": {},
   "outputs": [],
   "source": [
    "CL_kmeans(X_train, X_test, y_train, y_test, 16)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "11bbcb47",
   "metadata": {},
   "source": [
    "### Apply the CL-k-means model with biased classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b3c912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needs to work on the entire dataset to generate sufficient training samples for biased classifiers\n",
    "def Anomaly_IDS(X_train, X_test, y_train, y_test,n,b=100):\n",
    "    # CL-kmeans\n",
    "    km_cluster = MiniBatchKMeans(n_clusters=n,batch_size=b)\n",
    "    result = km_cluster.fit_predict(X_train)\n",
    "    result2 = km_cluster.predict(X_test)\n",
    "\n",
    "    count=0\n",
    "    a=np.zeros(n)\n",
    "    b=np.zeros(n)\n",
    "    for v in range(0,n):\n",
    "        for i in range(0,len(y_train)):\n",
    "            if result[i]==v:\n",
    "                if y_train[i]==1:\n",
    "                    a[v]=a[v]+1\n",
    "                else:\n",
    "                    b[v]=b[v]+1\n",
    "    list1=[]\n",
    "    list2=[]\n",
    "    for v in range(0,n):\n",
    "        if a[v]<=b[v]:\n",
    "            list1.append(v)\n",
    "        else: \n",
    "            list2.append(v)\n",
    "    for v in range(0,len(y_test)):\n",
    "        if result2[v] in list1:\n",
    "            result2[v]=0\n",
    "        elif result2[v] in list2:\n",
    "            result2[v]=1\n",
    "        else:\n",
    "            print(\"-1\")\n",
    "    print(classification_report(y_test, result2))\n",
    "    cm=confusion_matrix(y_test,result2)\n",
    "    acc=metrics.accuracy_score(y2,result2)\n",
    "    print(str(acc))\n",
    "    print(cm)\n",
    "    \n",
    "    #Biased classifier construction\n",
    "    count=0\n",
    "    print(len(y))\n",
    "    a=np.zeros(n)\n",
    "    b=np.zeros(n)\n",
    "    FNL=[]\n",
    "    FPL=[]\n",
    "    for v in range(0,n):\n",
    "        al=[]\n",
    "        bl=[]\n",
    "        for i in range(0,len(y)):   \n",
    "            if result[i]==v:        \n",
    "                if y[i]==1:        #label 1\n",
    "                    a[v]=a[v]+1\n",
    "                    al.append(i)\n",
    "                else:             #label 0\n",
    "                    b[v]=b[v]+1\n",
    "                    bl.append(i)\n",
    "        if a[v]<=b[v]:\n",
    "            FNL.extend(al)\n",
    "        else:\n",
    "            FPL.extend(bl)\n",
    "        #print(str(v)+\"=\"+str(a[v]/(a[v]+b[v])))\n",
    "        \n",
    "    dffp=df.iloc[FPL, :]\n",
    "    dffn=df.iloc[FNL, :]\n",
    "    dfva0=df[df['Label']==0]\n",
    "    dfva1=df[df['Label']==1]\n",
    "    \n",
    "    dffpp=dfva1.sample(n=None, frac=len(FPL)/dfva1.shape[0], replace=False, weights=None, random_state=None, axis=0)\n",
    "    dffnp=dfva0.sample(n=None, frac=len(FNL)/dfva0.shape[0], replace=False, weights=None, random_state=None, axis=0)\n",
    "    \n",
    "    dffp_f=pd.concat([dffp, dffpp])\n",
    "    dffn_f=pd.concat([dffn, dffnp])\n",
    "    \n",
    "    Xp = dffp_f.drop(['Label'],axis=1)  \n",
    "    yp = dffp_f.iloc[:, -1].values.reshape(-1,1)\n",
    "    yp=np.ravel(yp)\n",
    "\n",
    "    Xn = dffn_f.drop(['Label'],axis=1)  \n",
    "    yn = dffn_f.iloc[:, -1].values.reshape(-1,1)\n",
    "    yn=np.ravel(yn)\n",
    "    \n",
    "    rfp = RandomForestClassifier(random_state = 0)\n",
    "    rfp.fit(Xp,yp)\n",
    "    rfn = RandomForestClassifier(random_state = 0)\n",
    "    rfn.fit(Xn,yn)\n",
    "\n",
    "    dffnn_f=pd.concat([dffn, dffnp])\n",
    "    \n",
    "    Xnn = dffn_f.drop(['Label'],axis=1)  \n",
    "    ynn = dffn_f.iloc[:, -1].values.reshape(-1,1)\n",
    "    ynn=np.ravel(ynn)\n",
    "\n",
    "    rfnn = RandomForestClassifier(random_state = 0)\n",
    "    rfnn.fit(Xnn,ynn)\n",
    "\n",
    "    X2p = df2.drop(['Label'],axis=1) \n",
    "    y2p = df2.iloc[:, -1].values.reshape(-1,1)\n",
    "    y2p=np.ravel(y2p)\n",
    "\n",
    "    result2 = km_cluster.predict(X2p)\n",
    "\n",
    "    count=0\n",
    "    a=np.zeros(n)\n",
    "    b=np.zeros(n)\n",
    "    for v in range(0,n):\n",
    "        for i in range(0,len(y)):\n",
    "            if result[i]==v:\n",
    "                if y[i]==1:\n",
    "                    a[v]=a[v]+1\n",
    "                else:\n",
    "                    b[v]=b[v]+1\n",
    "    list1=[]\n",
    "    list2=[]\n",
    "    l1=[]\n",
    "    l0=[]\n",
    "    for v in range(0,n):\n",
    "        if a[v]<=b[v]:\n",
    "            list1.append(v)\n",
    "        else: \n",
    "            list2.append(v)\n",
    "    for v in range(0,len(y2p)):\n",
    "        if result2[v] in list1:\n",
    "            result2[v]=0\n",
    "            l0.append(v)\n",
    "        elif result2[v] in list2:\n",
    "            result2[v]=1\n",
    "            l1.append(v)\n",
    "        else:\n",
    "            print(\"-1\")\n",
    "    print(classification_report(y2p, result2))\n",
    "    cm=confusion_matrix(y2p,result2)\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4325d589",
   "metadata": {},
   "outputs": [],
   "source": [
    "Anomaly_IDS(X_train, X_test, y_train, y_test, 16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
