{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "083437a6-b852-45f1-8cef-a225f5097a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b9e85a1d-cae6-4e15-a5d6-3bbd364b0735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,precision_recall_fscore_support\n",
    "from sklearn.metrics import f1_score,roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12a47fb-194f-46c4-a245-7f693f8c9258",
   "metadata": {},
   "source": [
    "# Remove before submission!!!!!!!!!\n",
    "Read the sampled CICIDS2017 dataset\n",
    "\n",
    "The CICIDS2017 dataset is publicly available at: https://www.unb.ca/cic/datasets/ids-2017.html\n",
    "Due to the large size of this dataset, the sampled subsets of CICIDS2017 is used. The subsets are in the \"data\" folder.\n",
    "If you want to use this code on other datasets (e.g., CAN-intrusion dataset), just change the dataset name and follow the same steps. The models in this code are generic models that can be used in any intrusion detection/network traffic datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e14257d8-66cc-4732-8e5d-c7b853690862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read the sampled dataset\n",
    "# df=pd.read_csv('./data/CICIDS2017_sample_km.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "810363b9-0b84-4b5b-b832-14df15b1df80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df.drop(['Label'],axis=1).values\n",
    "# y = df.iloc[:, -1].values.reshape(-1,1)\n",
    "# y=np.ravel(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8233961b-43ee-40ce-b86f-ae399c855b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X,y, train_size = 0.8, test_size = 0.2, random_state = 0,stratify = y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "82cbdc26",
   "metadata": {},
   "source": [
    "# Anomaly-based IDS\n",
    "Generate the port-scan datasets for unknown attack detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2c5096b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./data/CICIDS2017_sample_km.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c1849cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    18225\n",
       "3     3042\n",
       "6     2180\n",
       "1     1966\n",
       "5     1255\n",
       "2       96\n",
       "4       36\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a39b8d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[df['Label'] != 5]\n",
    "df1['Label'][df1['Label'] > 0] = 1\n",
    "df1.to_csv('./data/CICIDS2017_sample_km_without_portscan.csv',index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a7217c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[df['Label'] == 5]\n",
    "df2['Label'][df2['Label'] == 5] = 1\n",
    "df2.to_csv('./data/CICIDS2017_sample_km_portscan.csv',index=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db9e4abd",
   "metadata": {},
   "source": [
    "# Read the generated datasets for unknown attack detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4acb0926",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('./data/CICIDS2017_sample_km_without_portscan.csv')\n",
    "df2 = pd.read_csv('./data/CICIDS2017_sample_km_portscan.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4c40fffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df1.drop(['Label'],axis=1).dtypes[df1.dtypes != 'object'].index\n",
    "df1[features] = df1[features].apply(\n",
    "    lambda x: (x - x.mean()) / (x.std()))\n",
    "df2[features] = df2[features].apply(\n",
    "    lambda x: (x - x.mean()) / (x.std()))\n",
    "df1 = df1.fillna(0)\n",
    "df2 = df2.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6578015f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    18225\n",
       "1     7320\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c6fe427d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "1    1255\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d95756c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2p=df1[df1['Label']==0]\n",
    "df2pp=df2p.sample(n=None, frac=1255/18225, replace=False, weights=None, random_state=None, axis=0)\n",
    "df2=pd.concat([df2, df2pp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9d331198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "1    1255\n",
       "0    1255\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5b9b1447",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "85b9031d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    19480\n",
       "1     8575\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(['Label'],axis=1) .values\n",
    "y = df.iloc[:, -1].values.reshape(-1,1)\n",
    "y=np.ravel(y)\n",
    "pd.Series(y).value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d5bb415",
   "metadata": {},
   "source": [
    "### Feature engineering (IG, FCBF, and KPCA)\n",
    "Feature selection by information gain (IG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d2cf8587",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "importances = mutual_info_classif(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e0c587a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the sum of importance scores\n",
    "f_list = sorted(zip(map(lambda x: round(x, 4), importances), features), reverse=True)\n",
    "Sum = 0\n",
    "fs = []\n",
    "for i in range(0, len(f_list)):\n",
    "    Sum = Sum + f_list[i][0]\n",
    "    fs.append(f_list[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1380117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the important features from top to bottom until the accumulated importance reaches 90%\n",
    "f_list2 = sorted(zip(map(lambda x: round(x, 4), importances/Sum), features), reverse=True)\n",
    "Sum2 = 0\n",
    "fs = []\n",
    "for i in range(0, len(f_list2)):\n",
    "    Sum2 = Sum2 + f_list2[i][0]\n",
    "    fs.append(f_list2[i][1])\n",
    "    if Sum2>=0.9:\n",
    "        break   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9c901e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fs = df[fs].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f9845bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28055, 50)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1856cf70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.34612159, -0.51326791, -0.27787307, ..., -0.13353417,\n",
       "        -0.05349902, -0.11333586],\n",
       "       [-0.3443274 , -0.51326791, -0.27787307, ..., -0.13353417,\n",
       "        -0.05349902, -0.11333586],\n",
       "       [-0.3443274 , -0.51326791, -0.27787307, ..., -0.13353417,\n",
       "        -0.05349902, -0.11333586],\n",
       "       ...,\n",
       "       [-0.36557442, -0.32578622, -0.26407322, ...,  0.31568956,\n",
       "        -0.01864425,  0.59183812],\n",
       "       [-0.36859622, -0.29367857, -0.27659309, ..., -0.13353417,\n",
       "        -0.04188076, -0.11333586],\n",
       "       [-0.36566885, -0.51326791, -0.27787307, ..., -0.13353417,\n",
       "        -0.05349902, -0.11333586]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d25454e2",
   "metadata": {},
   "source": [
    "### Feature selection by Fast Correlation Based Filter (FCBF)\n",
    "\n",
    "The module is imported from the GitHub repo: https://github.com/SantiagoEG/FCBF_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "75d12f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FCBF_module import FCBF, FCBFK, FCBFiP, get_i\n",
    "fcbf = FCBFK(k = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2002ec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fss = fcbf.fit_transform(X_fs,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b1bf19d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28055, 20)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cad339df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.34612159, -0.53319222, -0.34935843, ..., -0.42229765,\n",
       "        -0.2803002 , -0.41947688],\n",
       "       [-0.3443274 , -0.54906516, -0.34935843, ..., -0.42229765,\n",
       "        -0.2803002 , -0.41947688],\n",
       "       [-0.3443274 , -0.55544206, -0.34935843, ..., -0.42229765,\n",
       "        -0.2803002 , -0.41947688],\n",
       "       ...,\n",
       "       [-0.36557442,  1.46028278, -0.0910357 , ..., -0.2261399 ,\n",
       "        -0.16459897, -0.34668302],\n",
       "       [-0.36859622, -0.56375976, -0.34935843, ..., -0.42229762,\n",
       "        -0.28030009, -0.3574673 ],\n",
       "       [-0.36566885, -0.54469836, -0.34935843, ..., -0.42229765,\n",
       "        -0.2803002 , -0.41947688]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5625795b",
   "metadata": {},
   "source": [
    "Kernel principal component analysis (KPCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b6bc6257",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ede1dc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kpca = KernelPCA(n_components = 10, kernel = 'rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "82aa4294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KernelPCA(kernel=&#x27;rbf&#x27;, n_components=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KernelPCA</label><div class=\"sk-toggleable__content\"><pre>KernelPCA(kernel=&#x27;rbf&#x27;, n_components=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KernelPCA(kernel='rbf', n_components=10)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kpca.fit(X_fss, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "afbfc968",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_kpca = kpca.transform(X_fss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c1bd9f8f",
   "metadata": {},
   "source": [
    "Train-test split after feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fd98152f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_kpca[:len(df1)]\n",
    "y_train = y[:len(df1)]\n",
    "X_test = X_kpca[len(df1):]\n",
    "y_test = y[len(df1):]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d599081",
   "metadata": {},
   "source": [
    "Solve class-imbalance by SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4acc650d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    18225\n",
       "1     7320\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7e6eebac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote=SMOTE(n_jobs=-1,sampling_strategy={1:18225})\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b0900ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    18225\n",
       "1    18225\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "66207cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1255\n",
       "0    1255\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pd.Series(y_test).value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5b3f42d",
   "metadata": {},
   "source": [
    "## Apply the cluster labeling (CL) k-means method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "718ae556",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN,MeanShift\n",
    "from sklearn.cluster import SpectralClustering,AgglomerativeClustering,AffinityPropagation,Birch,MiniBatchKMeans,MeanShift \n",
    "from sklearn.mixture import GaussianMixture, BayesianGaussianMixture\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c6808e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CL_kmeans(X_train, X_test, y_train, y_test,n,b=100):\n",
    "    km_cluster = MiniBatchKMeans(n_clusters=n,batch_size=b)\n",
    "    result = km_cluster.fit_predict(X_train)\n",
    "    result2 = km_cluster.predict(X_test)\n",
    "\n",
    "    count=0\n",
    "    a=np.zeros(n)\n",
    "    b=np.zeros(n)\n",
    "    for v in range(0,n):\n",
    "        for i in range(0,len(y_train)):\n",
    "            if result[i]==v:\n",
    "                if y_train[i]==1:\n",
    "                    a[v]=a[v]+1\n",
    "                else:\n",
    "                    b[v]=b[v]+1\n",
    "    list1=[]\n",
    "    list2=[]\n",
    "    for v in range(0,n):\n",
    "        if a[v]<=b[v]:\n",
    "            list1.append(v)\n",
    "        else: \n",
    "            list2.append(v)\n",
    "    for v in range(0,len(y_test)):\n",
    "        if result2[v] in list1:\n",
    "            result2[v]=0\n",
    "        elif result2[v] in list2:\n",
    "            result2[v]=1\n",
    "        else:\n",
    "            print(\"-1\")\n",
    "    print(classification_report(y_test, result2))\n",
    "    cm=confusion_matrix(y_test,result2)\n",
    "    acc=metrics.accuracy_score(y_test,result2)\n",
    "    print(str(acc))\n",
    "    print(cm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3cecd907",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization of CL-k-means\n",
    "Tune \"k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8bc45e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 0.4406374501992032\n",
      "43 0.4191235059760956\n",
      "43 0.45776892430278887\n",
      "43 0.4231075697211155\n",
      "32 0.3705179282868526\n",
      "20 0.4581673306772908\n",
      "16 0.4952191235059761\n",
      "5 0.4701195219123506\n",
      "15 0.48446215139442234\n",
      "25 0.45976095617529883\n",
      "11 0.6864541832669323\n",
      "10 0.4784860557768924\n",
      "2 0.4087649402390438\n",
      "11 0.6876494023904383\n",
      "11 0.7051792828685259\n",
      "11 0.4956175298804781\n",
      "11 0.44581673306772907\n",
      "12 0.47729083665338645\n",
      "11 0.9342629482071713\n",
      "50 0.4450199203187251\n",
      "20.037932634353638\n",
      "Best score=0.9343\n",
      "Best parameters: n_clusters=11\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter optimization by BO-GP\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "from sklearn import metrics\n",
    "\n",
    "space  = [Integer(2, 50, name='n_clusters')]\n",
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    km_cluster = MiniBatchKMeans(batch_size=100, **params)\n",
    "    n=params['n_clusters']\n",
    "    \n",
    "    result = km_cluster.fit_predict(X_train)\n",
    "    result2 = km_cluster.predict(X_test)\n",
    "\n",
    "    count=0\n",
    "    a=np.zeros(n)\n",
    "    b=np.zeros(n)\n",
    "    for v in range(0,n):\n",
    "        for i in range(0,len(y_train)):\n",
    "            if result[i]==v:\n",
    "                if y_train[i]==1:\n",
    "                    a[v]=a[v]+1\n",
    "                else:\n",
    "                    b[v]=b[v]+1\n",
    "    list1=[]\n",
    "    list2=[]\n",
    "    for v in range(0,n):\n",
    "        if a[v]<=b[v]:\n",
    "            list1.append(v)\n",
    "        else: \n",
    "            list2.append(v)\n",
    "    for v in range(0,len(y_test)):\n",
    "        if result2[v] in list1:\n",
    "            result2[v]=0\n",
    "        elif result2[v] in list2:\n",
    "            result2[v]=1\n",
    "        else:\n",
    "            print(\"-1\")\n",
    "    cm=metrics.accuracy_score(y_test,result2)\n",
    "    print(str(n)+\" \"+str(cm))\n",
    "    return (1-cm)\n",
    "from skopt import gp_minimize\n",
    "import time\n",
    "t1=time.time()\n",
    "res_gp = gp_minimize(objective, space, n_calls=20, random_state=0)\n",
    "t2=time.time()\n",
    "print(t2-t1)\n",
    "print(\"Best score=%.4f\" % (1-res_gp.fun))\n",
    "print(\"\"\"Best parameters: n_clusters=%d\"\"\" % (res_gp.x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5bcbc5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 0.4155378486055777                                 \n",
      "46 0.6852589641434262                                                           \n",
      "37 0.39243027888446214                                                           \n",
      "12 0.4470119521912351                                                            \n",
      "37 0.4095617529880478                                                            \n",
      "17 0.47290836653386453                                                           \n",
      "11 0.4784860557768924                                                            \n",
      "12 0.4944223107569721                                                            \n",
      "21 0.601593625498008                                                             \n",
      "14 0.7063745019920319                                                            \n",
      "19 0.4681274900398406                                                            \n",
      "27 0.38605577689243026                                                           \n",
      "47 0.4446215139442231                                                            \n",
      "35 0.41155378486055777                                                           \n",
      "29 0.4163346613545817                                                            \n",
      "16 0.46334661354581674                                                           \n",
      "7 0.4756972111553785                                                             \n",
      "24 0.4721115537848606                                                            \n",
      "42 0.42191235059760956                                                           \n",
      "14 0.48167330677290837                                                           \n",
      "100%|██████████| 20/20 [00:24<00:00,  1.24s/trial, best loss: 0.2936254980079681]\n",
      "Random Forest: Hyperopt estimated optimum {'n_clusters': 14.0}\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter optimization by BO-TPE\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn import metrics\n",
    "\n",
    "def objective(params):\n",
    "    params = {\n",
    "        'n_clusters': int(params['n_clusters']), \n",
    "    }\n",
    "    km_cluster = MiniBatchKMeans(batch_size=100, **params)\n",
    "    n=params['n_clusters']\n",
    "    \n",
    "    result = km_cluster.fit_predict(X_train)\n",
    "    result2 = km_cluster.predict(X_test)\n",
    "\n",
    "    count=0\n",
    "    a=np.zeros(n)\n",
    "    b=np.zeros(n)\n",
    "    for v in range(0,n):\n",
    "        for i in range(0,len(y_train)):\n",
    "            if result[i]==v:\n",
    "                if y_train[i]==1:\n",
    "                    a[v]=a[v]+1\n",
    "                else:\n",
    "                    b[v]=b[v]+1\n",
    "    list1=[]\n",
    "    list2=[]\n",
    "    for v in range(0,n):\n",
    "        if a[v]<=b[v]:\n",
    "            list1.append(v)\n",
    "        else: \n",
    "            list2.append(v)\n",
    "    for v in range(0,len(y_test)):\n",
    "        if result2[v] in list1:\n",
    "            result2[v]=0\n",
    "        elif result2[v] in list2:\n",
    "            result2[v]=1\n",
    "        else:\n",
    "            print(\"-1\")\n",
    "    score=metrics.accuracy_score(y_test,result2)\n",
    "    print(str(params['n_clusters'])+\" \"+str(score))\n",
    "    return {'loss':1-score, 'status': STATUS_OK }\n",
    "space = {\n",
    "    'n_clusters': hp.quniform('n_clusters', 2, 50, 1),\n",
    "}\n",
    "\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20)\n",
    "print(\"Random Forest: Hyperopt estimated optimum {}\".format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "cedde670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.90      0.62      1255\n",
      "           1       0.06      0.01      0.01      1255\n",
      "\n",
      "    accuracy                           0.45      2510\n",
      "   macro avg       0.27      0.45      0.32      2510\n",
      "weighted avg       0.27      0.45      0.32      2510\n",
      "\n",
      "0.45179282868525894\n",
      "[[1126  129]\n",
      " [1247    8]]\n"
     ]
    }
   ],
   "source": [
    "CL_kmeans(X_train, X_test, y_train, y_test, 16)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "11bbcb47",
   "metadata": {},
   "source": [
    "### Apply the CL-k-means model with biased classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "90b3c912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needs to work on the entire dataset to generate sufficient training samples for biased classifiers\n",
    "def Anomaly_IDS(X_train, X_test, y_train, y_test,n,b=100):\n",
    "    # CL-kmeans\n",
    "    km_cluster = MiniBatchKMeans(n_clusters=n,batch_size=b)\n",
    "    result = km_cluster.fit_predict(X_train)\n",
    "    result2 = km_cluster.predict(X_test)\n",
    "\n",
    "    count=0\n",
    "    a=np.zeros(n)\n",
    "    b=np.zeros(n)\n",
    "    for v in range(0,n):\n",
    "        for i in range(0,len(y_train)):\n",
    "            if result[i]==v:\n",
    "                if y_train[i]==1:\n",
    "                    a[v]=a[v]+1\n",
    "                else:\n",
    "                    b[v]=b[v]+1\n",
    "    list1=[]\n",
    "    list2=[]\n",
    "    for v in range(0,n):\n",
    "        if a[v]<=b[v]:\n",
    "            list1.append(v)\n",
    "        else: \n",
    "            list2.append(v)\n",
    "    for v in range(0,len(y_test)):\n",
    "        if result2[v] in list1:\n",
    "            result2[v]=0\n",
    "        elif result2[v] in list2:\n",
    "            result2[v]=1\n",
    "        else:\n",
    "            print(\"-1\")\n",
    "    print(classification_report(y_test, result2))\n",
    "    cm=confusion_matrix(y_test,result2)\n",
    "    acc=metrics.accuracy_score(y_test,result2)\n",
    "    print(str(acc))\n",
    "    print(cm)\n",
    "    \n",
    "    #Biased classifier construction\n",
    "    count=0\n",
    "    print(len(y))\n",
    "    a=np.zeros(n)\n",
    "    b=np.zeros(n)\n",
    "    FNL=[]\n",
    "    FPL=[]\n",
    "    for v in range(0,n):\n",
    "        al=[]\n",
    "        bl=[]\n",
    "        for i in range(0,len(y)):   \n",
    "            if result[i]==v:        \n",
    "                if y[i]==1:        #label 1\n",
    "                    a[v]=a[v]+1\n",
    "                    al.append(i)\n",
    "                else:             #label 0\n",
    "                    b[v]=b[v]+1\n",
    "                    bl.append(i)\n",
    "        if a[v]<=b[v]:\n",
    "            FNL.extend(al)\n",
    "        else:\n",
    "            FPL.extend(bl)\n",
    "        #print(str(v)+\"=\"+str(a[v]/(a[v]+b[v])))\n",
    "        \n",
    "    dffp=df.iloc[FPL, :]\n",
    "    dffn=df.iloc[FNL, :]\n",
    "    dfva0=df[df['Label']==0]\n",
    "    dfva1=df[df['Label']==1]\n",
    "    \n",
    "    dffpp=dfva1.sample(n=None, frac=len(FPL)/dfva1.shape[0], replace=False, weights=None, random_state=None, axis=0)\n",
    "    dffnp=dfva0.sample(n=None, frac=len(FNL)/dfva0.shape[0], replace=False, weights=None, random_state=None, axis=0)\n",
    "    \n",
    "    dffp_f=pd.concat([dffp, dffpp])\n",
    "    dffn_f=pd.concat([dffn, dffnp])\n",
    "    \n",
    "    Xp = dffp_f.drop(['Label'],axis=1)  \n",
    "    yp = dffp_f.iloc[:, -1].values.reshape(-1,1)\n",
    "    yp=np.ravel(yp)\n",
    "\n",
    "    Xn = dffn_f.drop(['Label'],axis=1)  \n",
    "    yn = dffn_f.iloc[:, -1].values.reshape(-1,1)\n",
    "    yn=np.ravel(yn)\n",
    "    \n",
    "    rfp = RandomForestClassifier(random_state = 0)\n",
    "    rfp.fit(Xp,yp)\n",
    "    rfn = RandomForestClassifier(random_state = 0)\n",
    "    rfn.fit(Xn,yn)\n",
    "\n",
    "    dffnn_f=pd.concat([dffn, dffnp])\n",
    "    \n",
    "    Xnn = dffn_f.drop(['Label'],axis=1)  \n",
    "    ynn = dffn_f.iloc[:, -1].values.reshape(-1,1)\n",
    "    ynn=np.ravel(ynn)\n",
    "\n",
    "    rfnn = RandomForestClassifier(random_state = 0)\n",
    "    rfnn.fit(Xnn,ynn)\n",
    "\n",
    "    X2p = df2.drop(['Label'],axis=1) \n",
    "    y2p = df2.iloc[:, -1].values.reshape(-1,1)\n",
    "    y2p=np.ravel(y2p)\n",
    "\n",
    "    result2 = km_cluster.predict(X2p)\n",
    "\n",
    "    count=0\n",
    "    a=np.zeros(n)\n",
    "    b=np.zeros(n)\n",
    "    for v in range(0,n):\n",
    "        for i in range(0,len(y)):\n",
    "            if result[i]==v:\n",
    "                if y[i]==1:\n",
    "                    a[v]=a[v]+1\n",
    "                else:\n",
    "                    b[v]=b[v]+1\n",
    "    list1=[]\n",
    "    list2=[]\n",
    "    l1=[]\n",
    "    l0=[]\n",
    "    for v in range(0,n):\n",
    "        if a[v]<=b[v]:\n",
    "            list1.append(v)\n",
    "        else: \n",
    "            list2.append(v)\n",
    "    for v in range(0,len(y2p)):\n",
    "        if result2[v] in list1:\n",
    "            result2[v]=0\n",
    "            l0.append(v)\n",
    "        elif result2[v] in list2:\n",
    "            result2[v]=1\n",
    "            l1.append(v)\n",
    "        else:\n",
    "            print(\"-1\")\n",
    "    print(classification_report(y2p, result2))\n",
    "    cm=confusion_matrix(y2p,result2)\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4325d589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.93      0.76      1255\n",
      "           1       0.88      0.49      0.63      1255\n",
      "\n",
      "    accuracy                           0.71      2510\n",
      "   macro avg       0.76      0.71      0.69      2510\n",
      "weighted avg       0.76      0.71      0.69      2510\n",
      "\n",
      "0.7099601593625497\n",
      "[[1169   86]\n",
      " [ 642  613]]\n",
      "28055\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 77 features, but MiniBatchKMeans is expecting 10 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[121], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m----> 2\u001b[0m Anomaly_IDS(X_train, X_test, y_train, y_test, \u001b[39m16\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[120], line 99\u001b[0m, in \u001b[0;36mAnomaly_IDS\u001b[1;34m(X_train, X_test, y_train, y_test, n, b)\u001b[0m\n\u001b[0;32m     96\u001b[0m y2p \u001b[39m=\u001b[39m df2\u001b[39m.\u001b[39miloc[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m)\n\u001b[0;32m     97\u001b[0m y2p\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mravel(y2p)\n\u001b[1;32m---> 99\u001b[0m result2 \u001b[39m=\u001b[39m km_cluster\u001b[39m.\u001b[39;49mpredict(X2p)\n\u001b[0;32m    101\u001b[0m count\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[0;32m    102\u001b[0m a\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mzeros(n)\n",
      "File \u001b[1;32mc:\\Users\\tnl35\\Downloads\\CS_4371_GP-main(3)\\project_code\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1058\u001b[0m, in \u001b[0;36m_BaseKMeans.predict\u001b[1;34m(self, X, sample_weight)\u001b[0m\n\u001b[0;32m   1036\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Predict the closest cluster each sample in X belongs to.\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \n\u001b[0;32m   1038\u001b[0m \u001b[39mIn the vector quantization literature, `cluster_centers_` is called\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[39m    Index of the cluster each sample belongs to.\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1056\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m-> 1058\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_test_data(X)\n\u001b[0;32m   1059\u001b[0m sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X, dtype\u001b[39m=\u001b[39mX\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m   1061\u001b[0m labels \u001b[39m=\u001b[39m _labels_inertia_threadpool_limit(\n\u001b[0;32m   1062\u001b[0m     X,\n\u001b[0;32m   1063\u001b[0m     sample_weight,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1066\u001b[0m     return_inertia\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   1067\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\tnl35\\Downloads\\CS_4371_GP-main(3)\\project_code\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:934\u001b[0m, in \u001b[0;36m_BaseKMeans._check_test_data\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_test_data\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m--> 934\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    935\u001b[0m         X,\n\u001b[0;32m    936\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    937\u001b[0m         reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    938\u001b[0m         dtype\u001b[39m=\u001b[39;49m[np\u001b[39m.\u001b[39;49mfloat64, np\u001b[39m.\u001b[39;49mfloat32],\n\u001b[0;32m    939\u001b[0m         order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    940\u001b[0m         accept_large_sparse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    941\u001b[0m     )\n\u001b[0;32m    942\u001b[0m     \u001b[39mreturn\u001b[39;00m X\n",
      "File \u001b[1;32mc:\\Users\\tnl35\\Downloads\\CS_4371_GP-main(3)\\project_code\\Lib\\site-packages\\sklearn\\base.py:588\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    585\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    587\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m--> 588\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[0;32m    590\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\tnl35\\Downloads\\CS_4371_GP-main(3)\\project_code\\Lib\\site-packages\\sklearn\\base.py:389\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 389\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    390\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    391\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    392\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 77 features, but MiniBatchKMeans is expecting 10 features as input."
     ]
    }
   ],
   "source": [
    "from sklearn import *\n",
    "Anomaly_IDS(X_train, X_test, y_train, y_test, 16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
